{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fcec894",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b715631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pacs\n",
    "from mixstyle import MixStyle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f566d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ec42f",
   "metadata": {},
   "source": [
    "## Regarding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88da165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7\n",
    "CLASSES = [\"dog\", \"elephant\", \"giraffe\", \"guitar\", \"horse\", \"house\", \"person\"]\n",
    "DOMAINS = {\"art_painting\", \"cartoon\", \"photo\", \"sketch\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f852e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea520f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001 # Standard value for Adam: 0.001\n",
    "REGULARIZATION = 0 # Standard value for Adam: 0\n",
    "BETAS = (0.9, 0.999) # Standard values for Adam: (0.9, 0.999)\n",
    "MIX_P = 0.5\n",
    "MIX_ALPHA = 0.1 # Authors recommend to stick wiht alpha=0.1\n",
    "MIX_TYPE = 'random' # 'random' or 'crossdomain' (Authors report similar performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad6615",
   "metadata": {},
   "source": [
    "## Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ab49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for pretrained ResNet\n",
    "# image_transform = T.Compose([\n",
    "#     T.Resize(256),\n",
    "#     T.CenterCrop(224),\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc381c",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a84b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2ea28",
   "metadata": {},
   "source": [
    "## Model with MixStyle layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixStyleResNet(models.ResNet):\n",
    "    # Adapt ResNet-18 implementation from https://docs.pytorch.org/vision/main/_modules/torchvision/models/resnet.html\n",
    "    # https://github.com/KaiyangZhou/mixstyle-release/blob/master/reid/models/resnet_ms.py\n",
    "    def __init__(self):\n",
    "        super().__init__(models.resnet.BasicBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES)\n",
    "        self.mixstyle = MixStyle(p=MIX_P, alpha=MIX_ALPHA, mix=MIX_TYPE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.mixstyle(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.mixstyle(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc97cec",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(42)\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c39917",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6119fbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 11624), started 12 days, 5:36:23 ago. (Use '!kill 11624' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-de564465e4531513\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-de564465e4531513\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb82bc",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88de7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db9d8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, output):\n",
    "    batch_size = target.shape[0]\n",
    "    _, pred = torch.max(output, dim=-1)\n",
    "    correct = pred.eq(target).sum()\n",
    "    return correct.item() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572bc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, target_domain, data_loader, model, optimizer) -> tuple[float, float]:\n",
    "    \"\"\"train one epoch\"\"\"\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        step = (epoch - 1) * len(data_loader) + i + 1\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(target, out)\n",
    "        losses.update(loss.item(), out.shape[0])\n",
    "        accs.update(acc, out.shape[0])\n",
    "\n",
    "        writer.add_scalar(f'Loss/Train/target={target_domain}', loss.item(), step)\n",
    "        writer.add_scalar(f'Accuracy/Train/target={target_domain}', acc, step)\n",
    "\n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173b90b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd3c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, phase=\"val\") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            out = model(data)\n",
    "            loss = F.cross_entropy(out, target)\n",
    "\n",
    "            acc = accuracy(target, out)\n",
    "            losses.update(loss.item(), out.shape[0])\n",
    "            accs.update(acc, out.shape[0])\n",
    "    \n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0258",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585acb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da945fe508784f1596484c6f0ed3ade0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Target Domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization values excluding domain cartoon:\n",
      "\tmean: tensor([0.7512, 0.7332, 0.7101])\n",
      "\tstd: tensor([0.1835, 0.1886, 0.2020])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sampler option is mutually exclusive with shuffle",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNormalization values excluding domain \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_domain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mmean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_mean\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mstd: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_std\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m image_transform = T.Compose([\n\u001b[32m     12\u001b[39m     T.Resize(\u001b[32m256\u001b[39m),\n\u001b[32m     13\u001b[39m     T.CenterCrop(\u001b[32m224\u001b[39m),\n\u001b[32m     14\u001b[39m     T.ToTensor(),\n\u001b[32m     15\u001b[39m     T.Normalize(mean=img_mean, std=img_std)\n\u001b[32m     16\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m train_loader, test_loader = pacs.get_data_loaders(target_domain, train_batch_size=BATCH_SIZE, transform=image_transform, drop_last=(MIX_TYPE == \u001b[33m'\u001b[39m\u001b[33mcrossdomain\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     20\u001b[39m best_acc = \u001b[32m0\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS + \u001b[32m1\u001b[39m), desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_domain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\25 SS\\xAI-Proj\\domain_generalization\\pacs.py:63\u001b[39m, in \u001b[36mget_data_loaders\u001b[39m\u001b[34m(target_domain, train_batch_size, test_batch_size, shuffle_train, shuffle_test, transform, target_transform, drop_last)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_batch_size < \u001b[32m1\u001b[39m:\n\u001b[32m     61\u001b[39m     test_batch_size = \u001b[38;5;28mlen\u001b[39m(test_dataset)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m train_loader = DataLoader(\n\u001b[32m     64\u001b[39m     train_dataset, train_batch_size, shuffle_train, drop_last)\n\u001b[32m     65\u001b[39m test_loader = DataLoader(\n\u001b[32m     66\u001b[39m     test_dataset, test_batch_size, shuffle_test, drop_last)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m train_loader, test_loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:359\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m\n\u001b[32m    356\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind = _DatasetKind.Map\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msampler option is mutually exclusive with shuffle\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;66;03m# auto_collation with custom batch_sampler\u001b[39;00m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m batch_size != \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m shuffle \u001b[38;5;129;01mor\u001b[39;00m sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m drop_last:\n",
      "\u001b[31mValueError\u001b[39m: sampler option is mutually exclusive with shuffle"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for target_domain in tqdm(DOMAINS, desc=\"Target Domain\"):\n",
    "    model = MixStyleResNet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=BETAS, weight_decay=REGULARIZATION)\n",
    "\n",
    "    img_mean, img_std = pacs.get_nomalization_stats(target_domain)\n",
    "    print(f\"Normalization values excluding domain {target_domain}:\\n\\tmean: {img_mean}\\n\\tstd: {img_std}\")\n",
    "    image_transform = T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=img_mean, std=img_std)\n",
    "    ])\n",
    "\n",
    "    train_loader, test_loader = pacs.get_data_loaders(target_domain, train_batch_size=BATCH_SIZE, transform=image_transform)\n",
    "\n",
    "    best_acc = 0\n",
    "    for epoch in tqdm(range(1, EPOCHS + 1), desc=f\"Epoch ({target_domain})\"):\n",
    "        train_loss, train_acc = train(epoch, target_domain, train_loader, model, optimizer)\n",
    "        test_loss, test_acc = evaluate(test_loader, model)\n",
    "\n",
    "        writer.add_scalar(f\"Loss/Test/target={target_domain}\", test_loss, epoch)\n",
    "        writer.add_scalar(f\"Accuracy/Test/target={target_domain}\", test_acc, epoch)\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), f\"models/mixstyle/best_{target_domain}.pt\")\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"models/mixstyle/best_{target_domain}.pt\"))\n",
    "    _, acc = evaluate(test_loader, model, phase=\"final\")\n",
    "\n",
    "    results.append(acc)\n",
    "\n",
    "avg_acc = np.mean(results)\n",
    "worst_case_acc = np.min(results)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_acc}\\nWorst-case Performance: {worst_case_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_proj_t2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
