{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fcec894",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b715631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from data import pacs\n",
    "import models.resnet_ms as resnet_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f566d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ec42f",
   "metadata": {},
   "source": [
    "## Regarding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88da165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7\n",
    "CLASSES = [\"dog\", \"elephant\", \"giraffe\", \"guitar\", \"horse\", \"house\", \"person\"]\n",
    "DOMAINS = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f852e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea520f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "REGULARIZATION = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "MODEL = resnet_ms.resnet50_fc512_ms12_a0d1\n",
    "USE_PRETRAINED = True\n",
    "OPTIMIZER = optim.SGD\n",
    "OPTIMIZER_KWARGS = {\n",
    "    \"lr\": LEARNING_RATE,\n",
    "    \"weight_decay\": REGULARIZATION,\n",
    "    \"momentum\": MOMENTUM\n",
    "}\n",
    "SCHEDULER = optim.lr_scheduler.CosineAnnealingLR # optim.lr_scheduler.ReduceLROnPlateau\n",
    "SCHEDULER_KWARGS = {\"T_max\": EPOCHS} # {\"mode\": \"min\", \"patience\": 5}\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "EARLY_STOPPING_DELTA = 1e-5\n",
    "AUGMENTATIONS = ()\n",
    "NUM_SEEDS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad6615",
   "metadata": {},
   "source": [
    "## Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ab49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for pretrained ResNet\n",
    "pretrained_image_transform = T.Compose([\n",
    "    *AUGMENTATIONS,\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc381c",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a84b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2ea28",
   "metadata": {},
   "source": [
    "## Abstract model building, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3f6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model = lambda: MODEL(NUM_CLASSES, loss='softmax', pretrained=USE_PRETRAINED)\n",
    "build_optimizer = lambda model: OPTIMIZER(model.parameters(), **OPTIMIZER_KWARGS)\n",
    "build_scheduler = lambda optimizer: SCHEDULER(optimizer, **SCHEDULER_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc97cec",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705b34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "# torch.manual_seed(42)\n",
    "# if device == torch.device(\"cuda\"):\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c39917",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6119fbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25156), started 4 days, 21:33:29 ago. (Use '!kill 25156' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-44abf92cb8320f6e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-44abf92cb8320f6e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb82bc",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88de7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9d8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, output):\n",
    "    batch_size = target.shape[0]\n",
    "    _, pred = torch.max(output, dim=-1)\n",
    "    correct = pred.eq(target).sum()\n",
    "    return correct.item() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "572bc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch: int,\n",
    "        target_domain: str,\n",
    "        data_loader:torch.utils.data.DataLoader,\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer\n",
    "        ) -> tuple[float, float]:\n",
    "    \"\"\"train one epoch\"\"\"\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        step = (epoch - 1) * len(data_loader) + i + 1\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(target, out)\n",
    "        losses.update(loss.item(), out.shape[0])\n",
    "        accs.update(acc, out.shape[0])\n",
    "\n",
    "        writer.add_scalar(f'Loss/Train/target={target_domain}', loss.item(), step)\n",
    "        writer.add_scalar(f'Accuracy/Train/target={target_domain}', acc, step)\n",
    "\n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173b90b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd3c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader: torch.utils.data.DataLoader, model: nn.Module, phase=\"val\") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            out = model(data)\n",
    "\n",
    "            # The implementation returns only the feature vector rather than the classification logits.\n",
    "            # To compare the labels, we therefore must apply the classification layer manually:\n",
    "            out = model.classifier(out)\n",
    "\n",
    "            loss = F.cross_entropy(out, target)\n",
    "            acc = accuracy(target, out)\n",
    "\n",
    "            losses.update(loss.item(), out.shape[0])\n",
    "            accs.update(acc, out.shape[0])\n",
    "    \n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0258",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "585acb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e515e1cc4d4da1bc5291c76e90badf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Seeds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4583664590a4127b7dd31e206c21d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Target Domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     26\u001b[39m     image_transform = pretrained_image_transform\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m train_loader, test_loader, val_loader = pacs.get_data_loaders(target_domain,\n\u001b[32m     29\u001b[39m                                                               train_batch_size=BATCH_SIZE,\n\u001b[32m     30\u001b[39m                                                               split=\u001b[33m\"\u001b[39m\u001b[33mthreefold\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m                                                               transform=image_transform,\n\u001b[32m     32\u001b[39m                                                               shuffle_test=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     33\u001b[39m                                                               drop_last=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     34\u001b[39m                                                              )\n\u001b[32m     36\u001b[39m best_loss = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     37\u001b[39m patience_counter = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\25 SS\\xAI-Proj\\domain_generalization\\notebooks\\..\\data\\pacs.py:58\u001b[39m, in \u001b[36mget_data_loaders\u001b[39m\u001b[34m(target_domain, train_batch_size, test_batch_size, split, shuffle_train, shuffle_test, transform, target_transform, drop_last)\u001b[39m\n\u001b[32m     55\u001b[39m source_domains = domains - {target_domain}\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m split == \u001b[33m\"\u001b[39m\u001b[33mthreefold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     val_domain = random.choice(source_domains)\n\u001b[32m     59\u001b[39m     source_domains -= {val_domain}\n\u001b[32m     61\u001b[39m train_df = pacs[pacs[\u001b[33m'\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m'\u001b[39m].isin(source_domains)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\random.py:374\u001b[39m, in \u001b[36mRandom.choice\u001b[39m\u001b[34m(self, seq)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mCannot choose from an empty sequence\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m._randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[31mTypeError\u001b[39m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "all_results = {d: [] for d in DOMAINS}\n",
    "all_results['avgs'] = []\n",
    "all_results['worst'] = []\n",
    "\n",
    "for _ in tqdm(range(NUM_SEEDS), desc=\"Seeds\"):\n",
    "    results = {}\n",
    "\n",
    "    for target_domain in tqdm(DOMAINS, desc=\"Target Domain\"):\n",
    "        model = build_model()\n",
    "        model = model.to(device)\n",
    "\n",
    "        optimizer = build_optimizer(model)\n",
    "        scheduler = build_scheduler(optimizer)\n",
    "\n",
    "        if not USE_PRETRAINED:\n",
    "            img_mean, img_std = pacs.get_normalization_stats(target_domain)\n",
    "            print(f\"Normalization values excluding domain {target_domain}:\\n\\tmean: {img_mean}\\n\\tstd: {img_std}\")\n",
    "            image_transform = T.Compose([\n",
    "                *AUGMENTATIONS,\n",
    "                T.Resize(256),\n",
    "                T.CenterCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=img_mean, std=img_std)\n",
    "            ])\n",
    "        else:\n",
    "            image_transform = pretrained_image_transform\n",
    "\n",
    "        train_loader, test_loader, val_loader = pacs.get_data_loaders(target_domain,\n",
    "                                                                      train_batch_size=BATCH_SIZE,\n",
    "                                                                      split=\"threefold\",\n",
    "                                                                      transform=image_transform,\n",
    "                                                                      shuffle_test=True,\n",
    "                                                                      drop_last=True\n",
    "                                                                     )\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        for epoch in tqdm(range(1, EPOCHS + 1), desc=f\"Epoch ({target_domain})\"):\n",
    "            train_loss, train_acc = train(epoch, target_domain, train_loader, model, optimizer)\n",
    "            val_loss, val_acc = evaluate(val_loader, model)\n",
    "\n",
    "            writer.add_scalar(f\"Loss/Val/target={target_domain}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Accuracy/Val/target={target_domain}\", val_acc, epoch)\n",
    "\n",
    "            scheduler.step() # scheduler.step(test_loss)\n",
    "\n",
    "            if best_loss - val_loss < EARLY_STOPPING_DELTA and (patience_counter := patience_counter+1) > EARLY_STOPPING_PATIENCE:\n",
    "                break\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f\"../checkpoints/mixstyle/best_{target_domain}.pt\")\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"../checkpoints/mixstyle/best_{target_domain}.pt\"))\n",
    "        _, acc = evaluate(test_loader, model, phase=\"final\")\n",
    "\n",
    "        results[target_domain] = acc\n",
    "\n",
    "    avg_acc = np.mean([*results.values()])\n",
    "    worst_case_acc = np.min([*results.values()])\n",
    "\n",
    "    for d in DOMAINS:\n",
    "        all_results[d].append(results[d])\n",
    "    all_results['avgs'].append(avg_acc)\n",
    "    all_results['worst'].append(worst_case_acc)\n",
    "\n",
    "print(\"Average Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.mean(all_results[d]):.4f}, std: {np.std(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['avgs']):.4f}, std: {np.std(all_results['avgs']):.4f}\\n\"\n",
    "      \"Worst-case Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.min(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['worst']):.4f}, std: {np.std(all_results['worst']):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:\n",
      "\tart_painting: 0.8877, std: 0.0063\n",
      "\tcartoon: 0.7674, std: 0.0121\n",
      "\tphoto: 0.9818, std: 0.0007\n",
      "\tsketch: 0.7550, std: 0.0136\n",
      "\ttotal: 0.8480, std: 0.0005\n",
      "Worst-case Accuracy:\n",
      "\tart_painting: 0.8823\n",
      "\tcartoon: 0.7526\n",
      "\tphoto: 0.9808\n",
      "\tsketch: 0.7439\n",
      "\ttotal: 0.7478, std: 0.0036\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.mean(all_results[d]):.4f}, std: {np.std(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['avgs']):.4f}, std: {np.std(all_results['avgs']):.4f}\\n\"\n",
    "      \"Worst-case Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.min(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['worst']):.4f}, std: {np.std(all_results['worst']):.4f}\"\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_proj_t2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
