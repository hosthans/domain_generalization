{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bced796",
   "metadata": {},
   "source": [
    "# Evaluate on Office-Home dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcec894",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b715631d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afc95997f8443788672882c1d2b836a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4edf9edc634c3e9c5c2b7f6a6ba3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00003.parquet:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeba0617130d403daa7e0815df7708ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00003.parquet:   0%|          | 0.00/119M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad0ceb5ef72447f9cf4a1706906ce18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00003.parquet:   0%|          | 0.00/791M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4ffc0e48fb41cdaddc122661b0d354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/15588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from data import office_home\n",
    "import models.resnet_ms as resnet_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f566d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ec42f",
   "metadata": {},
   "source": [
    "## Regarding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88da165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 65\n",
    "CLASSES = [\"Alarm Clock\", \"Backpack\", \"Batteries\", \"Bed\", \"Bike\", \"Bottle\", \"Bucket\", \"Calculator\", \"Calendar\", \"Candles\", \"Chair\", \"Clipboards\", \"Computer\", \"Couch\", \"Curtains\", \"Desk Lamp\", \"Drill\", \"Eraser\", \"Exit Sign\", \"Fan\", \"File Cabinet\", \"Flipflops\", \"Flowers\", \"Folder\", \"Fork\", \"Glasses\", \"Hammer\", \"Helmet\", \"Kettle\", \"Keyboard\", \"Knives\",\n",
    "\"Lamp Shade\", \"Laptop\", \"Marker\", \"Monitor\", \"Mop\", \"Mouse\", \"Mug\", \"Notebook\", \"Oven\", \"Pan\", \"Paper Clip\", \"Pen\", \"Pencil\", \"Postit Notes\", \"Printer\", \"Push Pin\", \"Radio\", \"Refrigerator\", \"Ruler\", \"Scissors\", \"Screwdriver\", \"Shelf\", \"Sink\", \"Sneakers\", \"Soda\", \"Speaker\", \"Spoon\", \"Table\", \"Telephone\", \"Toothbrush\", \"Toys\", \"Trash Can\", \"TV\", \"Webcam\"]\n",
    "DOMAINS = [\"Art\", \"Clipart\", \"Product\", \"Real World\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f852e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea520f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "REGULARIZATION = 1e-3\n",
    "MODEL = resnet_ms.resnet18\n",
    "USE_PRETRAINED = True\n",
    "OPTIMIZER = optim.AdamW\n",
    "OPTIMIZER_KWARGS = {\n",
    "    \"lr\": LEARNING_RATE, # Standard value for AdamW: 1e-3\n",
    "    \"weight_decay\": REGULARIZATION # Standard value for AdamW: 1e-2\n",
    "}\n",
    "SCHEDULER = optim.lr_scheduler.ReduceLROnPlateau\n",
    "SCHEDULER_KWARGS = {\"mode\": \"min\", \"patience\": 3}\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "EARLY_STOPPING_DELTA = 1e-5\n",
    "AUGMENTATIONS = ()\n",
    "NUM_SEEDS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad6615",
   "metadata": {},
   "source": [
    "## Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ab49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for pretrained ResNet\n",
    "pretrained_image_transform = T.Compose([\n",
    "    *AUGMENTATIONS,\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc381c",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a84b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2ea28",
   "metadata": {},
   "source": [
    "## Abstract model building, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb3f6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model = lambda: MODEL(NUM_CLASSES, loss='softmax', pretrained=USE_PRETRAINED)\n",
    "build_optimizer = lambda model: OPTIMIZER(model.parameters(), **OPTIMIZER_KWARGS)\n",
    "build_scheduler = lambda optimizer: SCHEDULER(optimizer, **SCHEDULER_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc97cec",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "705b34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "# torch.manual_seed(42)\n",
    "# if device == torch.device(\"cuda\"):\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c39917",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6119fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/home/hans/anaconda3/envs/xai_proj_t2/bin/tensorboard\", line 6, in <module>\n",
       "    from tensorboard.main import run_main\n",
       "  File \"/home/hans/anaconda3/envs/xai_proj_t2/lib/python3.11/site-packages/tensorboard/main.py\", line 27, in <module>\n",
       "    from tensorboard import default\n",
       "  File \"/home/hans/anaconda3/envs/xai_proj_t2/lib/python3.11/site-packages/tensorboard/default.py\", line 33, in <module>\n",
       "    from tensorboard.plugins.core import core_plugin\n",
       "  File \"/home/hans/anaconda3/envs/xai_proj_t2/lib/python3.11/site-packages/tensorboard/plugins/core/core_plugin.py\", line 32, in <module>\n",
       "    from tensorboard.util import grpc_util\n",
       "  File \"/home/hans/anaconda3/envs/xai_proj_t2/lib/python3.11/site-packages/tensorboard/util/grpc_util.py\", line 24, in <module>\n",
       "    import grpc\n",
       "  File \"/home/hans/anaconda3/envs/xai_proj_t2/lib/python3.11/site-packages/grpc/__init__.py\", line 22, in <module>\n",
       "    from grpc import _compression\n",
       "  File \"/home/hans/anaconda3/envs/xai_proj_t2/lib/python3.11/site-packages/grpc/_compression.py\", line 20, in <module>\n",
       "    from grpc._cython import cygrpc\n",
       "ImportError: /home/hans/anaconda3/envs/xai_proj_t2/lib/python3.11/site-packages/grpc/_cython/../../../.././libre2.so.11: undefined symbol: _ZN4absl12lts_202501275MutexD1Ev"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb82bc",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88de7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9d8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, output):\n",
    "    batch_size = target.shape[0]\n",
    "    _, pred = torch.max(output, dim=-1)\n",
    "    correct = pred.eq(target).sum()\n",
    "    return correct.item() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "572bc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch: int,\n",
    "        target_domain: str,\n",
    "        data_loader:torch.utils.data.DataLoader,\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer\n",
    "        ) -> tuple[float, float]:\n",
    "    \"\"\"train one epoch\"\"\"\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        step = (epoch - 1) * len(data_loader) + i + 1\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(target, out)\n",
    "        losses.update(loss.item(), out.shape[0])\n",
    "        accs.update(acc, out.shape[0])\n",
    "\n",
    "        writer.add_scalar(f'Loss/Train/target={target_domain}', loss.item(), step)\n",
    "        writer.add_scalar(f'Accuracy/Train/target={target_domain}', acc, step)\n",
    "\n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173b90b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd3c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader: torch.utils.data.DataLoader, model: nn.Module, phase=\"val\") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            out = model(data)\n",
    "\n",
    "            # The implementation returns only the feature vector rather than the classification logits.\n",
    "            # To compare the labels, we therefore must apply the classification layer manually:\n",
    "            out = model.classifier(out)\n",
    "\n",
    "            loss = F.cross_entropy(out, target)\n",
    "            acc = accuracy(target, out)\n",
    "\n",
    "            losses.update(loss.item(), out.shape[0])\n",
    "            accs.update(acc, out.shape[0])\n",
    "    \n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0258",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "585acb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b948b2fd064cc396d069deb7e27681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Seeds:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac2863306634a1d899534c32ececf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Target Domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02838030a0a74ac4aaec189fbb7203a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (Art):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dd4c8d9c964710927ea8b7055bc501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (Clipart):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33a17f057f543d8bfebd6bed663925e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (Product):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f579f9e8816f4a6e97238c129d3c3bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (Real World):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:\n",
      "\tArt: 0.4847, std: 0.0000\n",
      "\tClipart: 0.3670, std: 0.0000\n",
      "\tProduct: 0.5894, std: 0.0000\n",
      "\tReal World: 0.6101, std: 0.0000\n",
      "\ttotal: 0.5128, std: 0.0000\n",
      "Worst-case Accuracy:\n",
      "\tArt: 0.4847\n",
      "\tClipart: 0.3670\n",
      "\tProduct: 0.5894\n",
      "\tReal World: 0.6101\n",
      "\ttotal: 0.3670, std: 0.0000\n"
     ]
    }
   ],
   "source": [
    "all_results = {d: [] for d in DOMAINS}\n",
    "all_results['avgs'] = []\n",
    "all_results['worst'] = []\n",
    "\n",
    "for _ in tqdm(range(NUM_SEEDS), desc=\"Seeds\"):\n",
    "    results = {}\n",
    "\n",
    "    for target_domain in tqdm(DOMAINS, desc=\"Target Domain\"):\n",
    "        model = build_model()\n",
    "        model = model.to(device)\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"classifier\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        optimizer = build_optimizer(model)\n",
    "        scheduler = build_scheduler(optimizer)\n",
    "\n",
    "        if not USE_PRETRAINED:\n",
    "            img_mean, img_std = office_home.get_normalization_stats(target_domain)\n",
    "            print(f\"Normalization values excluding domain {target_domain}:\\n\\tmean: {img_mean}\\n\\tstd: {img_std}\")\n",
    "            image_transform = T.Compose([\n",
    "                *AUGMENTATIONS,\n",
    "                T.Resize(256),\n",
    "                T.CenterCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=img_mean, std=img_std)\n",
    "            ])\n",
    "        else:\n",
    "            image_transform = pretrained_image_transform\n",
    "\n",
    "        train_loader, test_loader = office_home.get_data_loaders(target_domain, train_batch_size=BATCH_SIZE, transform=image_transform, shuffle_test=True, drop_last=True)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        for epoch in tqdm(range(1, EPOCHS + 1), desc=f\"Epoch ({target_domain})\"):\n",
    "            train_loss, train_acc = train(epoch, target_domain, train_loader, model, optimizer)\n",
    "            test_loss, test_acc = evaluate(test_loader, model)\n",
    "\n",
    "            writer.add_scalar(f\"Loss/Test/target={target_domain}\", test_loss, epoch)\n",
    "            writer.add_scalar(f\"Accuracy/Test/target={target_domain}\", test_acc, epoch)\n",
    "\n",
    "            scheduler.step(test_loss)\n",
    "\n",
    "            if best_loss - test_loss < EARLY_STOPPING_DELTA and (patience_counter := patience_counter+1) > EARLY_STOPPING_PATIENCE:\n",
    "                break\n",
    "\n",
    "            if test_loss < best_loss:\n",
    "                best_acc = test_acc\n",
    "                torch.save(model.state_dict(), f\"../checkpoints/mixstyle/best_{target_domain}.pt\")\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"../checkpoints/mixstyle/best_{target_domain}.pt\"))\n",
    "        _, acc = evaluate(test_loader, model, phase=\"final\")\n",
    "\n",
    "        results[target_domain] = acc\n",
    "\n",
    "    avg_acc = np.mean([*results.values()])\n",
    "    worst_case_acc = np.min([*results.values()])\n",
    "\n",
    "    for d in DOMAINS:\n",
    "        all_results[d].append(results[d])\n",
    "    all_results['avgs'].append(avg_acc)\n",
    "    all_results['worst'].append(worst_case_acc)\n",
    "\n",
    "print(\"Average Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.mean(all_results[d]):.4f}, std: {np.std(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['avgs']):.4f}, std: {np.std(all_results['avgs']):.4f}\\n\"\n",
    "      \"Worst-case Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.min(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['worst']):.4f}, std: {np.std(all_results['worst']):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:\n",
      "\tart_painting: 0.8934, std: 0.0036\n",
      "\tcartoon: 0.7596, std: 0.0041\n",
      "\tphoto: 0.9774, std: 0.0030\n",
      "\tsketch: 0.7298, std: 0.0048\n",
      "\ttotal: 0.8400, std: 0.0033\n",
      "Worst-case Accuracy:\n",
      "\tart_painting: 0.8887\n",
      "\tcartoon: 0.7564\n",
      "\tphoto: 0.9736\n",
      "\tsketch: 0.7235\n",
      "\ttotal: 0.7298, std: 0.0048\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.mean(all_results[d]):.4f}, std: {np.std(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['avgs']):.4f}, std: {np.std(all_results['avgs']):.4f}\\n\"\n",
    "      \"Worst-case Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.min(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['worst']):.4f}, std: {np.std(all_results['worst']):.4f}\"\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_proj_t2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
