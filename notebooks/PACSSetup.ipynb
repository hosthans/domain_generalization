{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fcec894",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from data import pacs\n",
    "import models.resnet_ms as resnet_ms\n",
    "import models.custom_models as custom_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f566d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ec42f",
   "metadata": {},
   "source": [
    "## Regarding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88da165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7\n",
    "CLASSES = [\"dog\", \"elephant\", \"giraffe\", \"guitar\", \"horse\", \"house\", \"person\"]\n",
    "DOMAINS = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f852e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea520f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "REGULARIZATION = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "MODEL = resnet_ms.resnet50_fc512_ms12_a0d1\n",
    "USE_PRETRAINED = True\n",
    "OPTIMIZER = optim.SGD\n",
    "OPTIMIZER_KWARGS = {\n",
    "    \"lr\": LEARNING_RATE,\n",
    "    \"weight_decay\": REGULARIZATION,\n",
    "    \"momentum\": MOMENTUM\n",
    "}\n",
    "SCHEDULER = optim.lr_scheduler.CosineAnnealingLR # optim.lr_scheduler.ReduceLROnPlateau\n",
    "SCHEDULER_KWARGS = {\"T_max\": EPOCHS} # {\"mode\": \"min\", \"patience\": 5}\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "EARLY_STOPPING_DELTA = 1e-5\n",
    "AUGMENTATIONS = ()\n",
    "NUM_SEEDS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad6615",
   "metadata": {},
   "source": [
    "## Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54ab49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for pretrained ResNet\n",
    "pretrained_image_transform = T.Compose([\n",
    "    *AUGMENTATIONS,\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc381c",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a84b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2ea28",
   "metadata": {},
   "source": [
    "## Abstract model building, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb3f6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model = lambda: MODEL(NUM_CLASSES, loss='softmax', pretrained=USE_PRETRAINED)\n",
    "build_optimizer = lambda model: OPTIMIZER(model.parameters(), **OPTIMIZER_KWARGS)\n",
    "build_scheduler = lambda optimizer: SCHEDULER(optimizer, **SCHEDULER_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc97cec",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "705b34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "# torch.manual_seed(42)\n",
    "# if device == torch.device(\"cuda\"):\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c39917",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6119fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25156), started 4 days, 3:39:41 ago. (Use '!kill 25156' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bfee7aef6a606a4b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bfee7aef6a606a4b\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb82bc",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88de7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db9d8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, output):\n",
    "    batch_size = target.shape[0]\n",
    "    _, pred = torch.max(output, dim=-1)\n",
    "    correct = pred.eq(target).sum()\n",
    "    return correct.item() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "572bc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch: int,\n",
    "        target_domain: str,\n",
    "        data_loader:torch.utils.data.DataLoader,\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer\n",
    "        ) -> tuple[float, float]:\n",
    "    \"\"\"train one epoch\"\"\"\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        step = (epoch - 1) * len(data_loader) + i + 1\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(target, out)\n",
    "        losses.update(loss.item(), out.shape[0])\n",
    "        accs.update(acc, out.shape[0])\n",
    "\n",
    "        writer.add_scalar(f'Loss/Train/target={target_domain}', loss.item(), step)\n",
    "        writer.add_scalar(f'Accuracy/Train/target={target_domain}', acc, step)\n",
    "\n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173b90b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfd3c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader: torch.utils.data.DataLoader, model: nn.Module, phase=\"val\") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            out = model(data)\n",
    "\n",
    "            # The implementation returns only the feature vector rather than the classification logits.\n",
    "            # To compare the labels, we therefore must apply the classification layer manually:\n",
    "            out = model.classifier(out)\n",
    "\n",
    "            loss = F.cross_entropy(out, target)\n",
    "            acc = accuracy(target, out)\n",
    "\n",
    "            losses.update(loss.item(), out.shape[0])\n",
    "            accs.update(acc, out.shape[0])\n",
    "    \n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0258",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585acb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ef5630398e4071a5fc7de7bb0fa53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Seeds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dcf97c94e246a4a81cca7568663c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Target Domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af85b0766e74c07b75981c2803f3b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (art_painting):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce99a4acbec94d0d8dfdc45c06a79e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (cartoon):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c980651774e40ee83d22d939822528a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (photo):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d462a6d49f5b4794b244861ebfb70068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (sketch):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d621b13239844ec9a0ae256f9c273c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Target Domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d03b64797924f2f85030120b7ee1a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (art_painting):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf12df2b5d04c2e952f7037692954e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (cartoon):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639d0c2608ec4dac92c0d100e1e87f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (photo):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea3e4c7ccd14390a881a24a6d4d3009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (sketch):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19a4a0dce1447f8bed87d83920214da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Target Domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4966679296594271877b72d0c05f07fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (art_painting):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03ac450d7d84c65b1631ea8ebb3b3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (cartoon):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b62fa439e6a40888ea3d56366c8704c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (photo):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert MixStyle after the following layers: ['layer1', 'layer2']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ef4d9ef4964c02aecf29e569ad84a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (sketch):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:\n",
      "\tart_painting: 0.8877, std: 0.0063\n",
      "\tcartoon: 0.7674, std: 0.0121\n",
      "\tphoto: 0.9818, std: 0.0007\n",
      "\tsketch: 0.7550, std: 0.0136\n",
      "\ttotal: 0.8480, std: 0.0005\n",
      "Worst-case Accuracy:\n",
      "\tart_painting: 0.8823\n",
      "\tcartoon: 0.7526\n",
      "\tphoto: 0.9808\n",
      "\tsketch: 0.7439\n",
      "\ttotal: 0.7478, std: 0.0036\n"
     ]
    }
   ],
   "source": [
    "all_results = {d: [] for d in DOMAINS}\n",
    "all_results['avgs'] = []\n",
    "all_results['worst'] = []\n",
    "\n",
    "for _ in tqdm(range(NUM_SEEDS), desc=\"Seeds\"):\n",
    "    results = {}\n",
    "\n",
    "    for target_domain in tqdm(DOMAINS, desc=\"Target Domain\"):\n",
    "        model = build_model()\n",
    "        model = model.to(device)\n",
    "\n",
    "        optimizer = build_optimizer(model)\n",
    "        scheduler = build_scheduler(optimizer)\n",
    "\n",
    "        if not USE_PRETRAINED:\n",
    "            img_mean, img_std = pacs.get_normalization_stats(target_domain)\n",
    "            print(f\"Normalization values excluding domain {target_domain}:\\n\\tmean: {img_mean}\\n\\tstd: {img_std}\")\n",
    "            image_transform = T.Compose([\n",
    "                *AUGMENTATIONS,\n",
    "                T.Resize(256),\n",
    "                T.CenterCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=img_mean, std=img_std)\n",
    "            ])\n",
    "        else:\n",
    "            image_transform = pretrained_image_transform\n",
    "\n",
    "        train_loader, val_loader = pacs.get_data_loaders(target_domain, train_batch_size=BATCH_SIZE, transform=image_transform, shuffle_test=True, drop_last=True)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        for epoch in tqdm(range(1, EPOCHS + 1), desc=f\"Epoch ({target_domain})\"):\n",
    "            train_loss, train_acc = train(epoch, target_domain, train_loader, model, optimizer)\n",
    "            val_loss, val_acc = evaluate(val_loader, model)\n",
    "\n",
    "            writer.add_scalar(f\"Loss/Test/target={target_domain}\", val_loss, epoch)\n",
    "            writer.add_scalar(f\"Accuracy/Test/target={target_domain}\", val_acc, epoch)\n",
    "\n",
    "            scheduler.step() # scheduler.step(test_loss)\n",
    "\n",
    "            if best_loss - val_loss < EARLY_STOPPING_DELTA and (patience_counter := patience_counter+1) > EARLY_STOPPING_PATIENCE:\n",
    "                break\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f\"../checkpoints/mixstyle/best_{target_domain}.pt\")\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"../checkpoints/mixstyle/best_{target_domain}.pt\"))\n",
    "        _, acc = evaluate(val_loader, model, phase=\"final\")\n",
    "\n",
    "        results[target_domain] = acc\n",
    "\n",
    "    avg_acc = np.mean([*results.values()])\n",
    "    worst_case_acc = np.min([*results.values()])\n",
    "\n",
    "    for d in DOMAINS:\n",
    "        all_results[d].append(results[d])\n",
    "    all_results['avgs'].append(avg_acc)\n",
    "    all_results['worst'].append(worst_case_acc)\n",
    "\n",
    "print(\"Average Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.mean(all_results[d]):.4f}, std: {np.std(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['avgs']):.4f}, std: {np.std(all_results['avgs']):.4f}\\n\"\n",
    "      \"Worst-case Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.min(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['worst']):.4f}, std: {np.std(all_results['worst']):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b5bd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:\n",
      "\tart_painting: 0.8877, std: 0.0063\n",
      "\tcartoon: 0.7674, std: 0.0121\n",
      "\tphoto: 0.9818, std: 0.0007\n",
      "\tsketch: 0.7550, std: 0.0136\n",
      "\ttotal: 0.8480, std: 0.0005\n",
      "Worst-case Accuracy:\n",
      "\tart_painting: 0.8823\n",
      "\tcartoon: 0.7526\n",
      "\tphoto: 0.9808\n",
      "\tsketch: 0.7439\n",
      "\ttotal: 0.7478, std: 0.0036\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.mean(all_results[d]):.4f}, std: {np.std(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['avgs']):.4f}, std: {np.std(all_results['avgs']):.4f}\\n\"\n",
    "      \"Worst-case Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.min(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['worst']):.4f}, std: {np.std(all_results['worst']):.4f}\"\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_proj_t2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
