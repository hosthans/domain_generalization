{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bced796",
   "metadata": {},
   "source": [
    "# Evaluate on Office-Home dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcec894",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b715631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from data import office_home\n",
    "import models.resnet_ms as resnet_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f566d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ec42f",
   "metadata": {},
   "source": [
    "## Regarding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88da165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 65\n",
    "CLASSES = [\"Alarm Clock\", \"Backpack\", \"Batteries\", \"Bed\", \"Bike\", \"Bottle\", \"Bucket\", \"Calculator\", \"Calendar\", \"Candles\", \"Chair\", \"Clipboards\", \"Computer\", \"Couch\", \"Curtains\", \"Desk Lamp\", \"Drill\", \"Eraser\", \"Exit Sign\", \"Fan\", \"File Cabinet\", \"Flipflops\", \"Flowers\", \"Folder\", \"Fork\", \"Glasses\", \"Hammer\", \"Helmet\", \"Kettle\", \"Keyboard\", \"Knives\",\n",
    "\"Lamp Shade\", \"Laptop\", \"Marker\", \"Monitor\", \"Mop\", \"Mouse\", \"Mug\", \"Notebook\", \"Oven\", \"Pan\", \"Paper Clip\", \"Pen\", \"Pencil\", \"Postit Notes\", \"Printer\", \"Push Pin\", \"Radio\", \"Refrigerator\", \"Ruler\", \"Scissors\", \"Screwdriver\", \"Shelf\", \"Sink\", \"Sneakers\", \"Soda\", \"Speaker\", \"Spoon\", \"Table\", \"Telephone\", \"Toothbrush\", \"Toys\", \"Trash Can\", \"TV\", \"Webcam\"]\n",
    "DOMAINS = [\"Art\", \"Clipart\", \"Product\", \"Real World\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f852e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea520f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "REGULARIZATION = 1e-3\n",
    "MODEL = resnet_ms.resnet18\n",
    "USE_PRETRAINED = True\n",
    "OPTIMIZER = optim.AdamW\n",
    "OPTIMIZER_KWARGS = {\n",
    "    \"lr\": LEARNING_RATE, # Standard value for AdamW: 1e-3\n",
    "    \"weight_decay\": REGULARIZATION # Standard value for AdamW: 1e-2\n",
    "}\n",
    "SCHEDULER = optim.lr_scheduler.ReduceLROnPlateau\n",
    "SCHEDULER_KWARGS = {\"mode\": \"min\", \"patience\": 3}\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "EARLY_STOPPING_DELTA = 1e-5\n",
    "AUGMENTATIONS = ()\n",
    "NUM_SEEDS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad6615",
   "metadata": {},
   "source": [
    "## Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ab49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for pretrained ResNet\n",
    "pretrained_image_transform = T.Compose([\n",
    "    *AUGMENTATIONS,\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc381c",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a84b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2ea28",
   "metadata": {},
   "source": [
    "## Abstract model building, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3f6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model = lambda: MODEL(NUM_CLASSES, loss='softmax', pretrained=USE_PRETRAINED)\n",
    "build_optimizer = lambda model: OPTIMIZER(model.parameters(), **OPTIMIZER_KWARGS)\n",
    "build_scheduler = lambda optimizer: SCHEDULER(optimizer, **SCHEDULER_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc97cec",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705b34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "# torch.manual_seed(42)\n",
    "# if device == torch.device(\"cuda\"):\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c39917",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6119fbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12812), started 8 days, 2:31:35 ago. (Use '!kill 12812' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8581149b09cef2ef\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8581149b09cef2ef\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb82bc",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88de7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9d8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, output):\n",
    "    batch_size = target.shape[0]\n",
    "    _, pred = torch.max(output, dim=-1)\n",
    "    correct = pred.eq(target).sum()\n",
    "    return correct.item() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "572bc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch: int,\n",
    "        target_domain: str,\n",
    "        data_loader:torch.utils.data.DataLoader,\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer\n",
    "        ) -> tuple[float, float]:\n",
    "    \"\"\"train one epoch\"\"\"\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        step = (epoch - 1) * len(data_loader) + i + 1\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(target, out)\n",
    "        losses.update(loss.item(), out.shape[0])\n",
    "        accs.update(acc, out.shape[0])\n",
    "\n",
    "        writer.add_scalar(f'Loss/Train/target={target_domain}', loss.item(), step)\n",
    "        writer.add_scalar(f'Accuracy/Train/target={target_domain}', acc, step)\n",
    "\n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173b90b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd3c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader: torch.utils.data.DataLoader, model: nn.Module, phase=\"val\") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            out = model(data)\n",
    "\n",
    "            # The implementation returns only the feature vector rather than the classification logits.\n",
    "            # To compare the labels, we therefore must apply the classification layer manually:\n",
    "            out = model.classifier(out)\n",
    "\n",
    "            loss = F.cross_entropy(out, target)\n",
    "            acc = accuracy(target, out)\n",
    "\n",
    "            losses.update(loss.item(), out.shape[0])\n",
    "            accs.update(acc, out.shape[0])\n",
    "    \n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0258",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585acb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722beb6eb4ea46a295723f97e7ba09f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Seeds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b365b497893474d9797318da73e3b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Target Domain:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938c0898a72c467fa4fd3a1dc0b044de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (Art):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace8d6ab5c4b4180a43855d98b49a6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch (Clipart):   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m patience_counter = \u001b[32m0\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS + \u001b[32m1\u001b[39m), desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_domain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     train_loss, train_acc = train(epoch, target_domain, train_loader, model, optimizer)\n\u001b[32m     34\u001b[39m     test_loss, test_acc = evaluate(test_loader, model)\n\u001b[32m     36\u001b[39m     writer.add_scalar(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoss/Test/target=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_domain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, test_loss, epoch)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(epoch, target_domain, data_loader, model, optimizer)\u001b[39m\n\u001b[32m      9\u001b[39m losses = AverageMeter()\n\u001b[32m     10\u001b[39m accs = AverageMeter()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[32m     13\u001b[39m     step = (epoch - \u001b[32m1\u001b[39m) * \u001b[38;5;28mlen\u001b[39m(data_loader) + i + \u001b[32m1\u001b[39m\n\u001b[32m     14\u001b[39m     data = data.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\25 SS\\xAI-Proj\\domain_generalization\\notebooks\\..\\data\\office_home.py:26\u001b[39m, in \u001b[36mOfficeHomeDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     25\u001b[39m     idx = \u001b[38;5;28mself\u001b[39m.indices[idx]\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     item = \u001b[38;5;28mself\u001b[39m.hf_dataset[idx]\n\u001b[32m     28\u001b[39m     image, label = item[\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m], item[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, Image.Image):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\arrow_dataset.py:2782\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2780\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   2781\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2782\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\arrow_dataset.py:2767\u001b[39m, in \u001b[36mDataset._getitem\u001b[39m\u001b[34m(self, key, **kwargs)\u001b[39m\n\u001b[32m   2765\u001b[39m formatter = get_formatter(format_type, features=\u001b[38;5;28mself\u001b[39m._info.features, **format_kwargs)\n\u001b[32m   2766\u001b[39m pa_subtable = query_table(\u001b[38;5;28mself\u001b[39m._data, key, indices=\u001b[38;5;28mself\u001b[39m._indices)\n\u001b[32m-> \u001b[39m\u001b[32m2767\u001b[39m formatted_output = format_table(\n\u001b[32m   2768\u001b[39m     pa_subtable, key, formatter=formatter, format_columns=format_columns, output_all_columns=output_all_columns\n\u001b[32m   2769\u001b[39m )\n\u001b[32m   2770\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\formatting\\formatting.py:658\u001b[39m, in \u001b[36mformat_table\u001b[39m\u001b[34m(table, key, formatter, format_columns, output_all_columns)\u001b[39m\n\u001b[32m    656\u001b[39m python_formatter = PythonFormatter(features=formatter.features)\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m formatter(pa_table, query_type=query_type)\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    660\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\formatting\\formatting.py:411\u001b[39m, in \u001b[36mFormatter.__call__\u001b[39m\u001b[34m(self, pa_table, query_type)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa.Table, query_type: \u001b[38;5;28mstr\u001b[39m) -> Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_row(pa_table)\n\u001b[32m    412\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    413\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_column(pa_table)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\formatting\\formatting.py:460\u001b[39m, in \u001b[36mPythonFormatter.format_row\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    459\u001b[39m row = \u001b[38;5;28mself\u001b[39m.python_arrow_extractor().extract_row(pa_table)\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m row = \u001b[38;5;28mself\u001b[39m.python_features_decoder.decode_row(row)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\formatting\\formatting.py:225\u001b[39m, in \u001b[36mPythonFeaturesDecoder.decode_row\u001b[39m\u001b[34m(self, row)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.features.decode_example(row, token_per_repo_id=\u001b[38;5;28mself\u001b[39m.token_per_repo_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.features \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\features\\features.py:2048\u001b[39m, in \u001b[36mFeatures.decode_example\u001b[39m\u001b[34m(self, example, token_per_repo_id)\u001b[39m\n\u001b[32m   2034\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2035\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[32m   2036\u001b[39m \n\u001b[32m   2037\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2045\u001b[39m \u001b[33;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[32m   2046\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2048\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m   2049\u001b[39m         column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)\n\u001b[32m   2050\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._column_requires_decoding[column_name]\n\u001b[32m   2051\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[32m   2052\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[32m   2053\u001b[39m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[32m   2054\u001b[39m         )\n\u001b[32m   2055\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\features\\features.py:2049\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   2034\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2035\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[32m   2036\u001b[39m \n\u001b[32m   2037\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2045\u001b[39m \u001b[33;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[32m   2046\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2048\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m-> \u001b[39m\u001b[32m2049\u001b[39m         column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)\n\u001b[32m   2050\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._column_requires_decoding[column_name]\n\u001b[32m   2051\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[32m   2052\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[32m   2053\u001b[39m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[32m   2054\u001b[39m         )\n\u001b[32m   2055\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\features\\features.py:1407\u001b[39m, in \u001b[36mdecode_nested_example\u001b[39m\u001b[34m(schema, obj, token_per_repo_id)\u001b[39m\n\u001b[32m   1404\u001b[39m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[32m   1405\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdecode_example\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdecode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1406\u001b[39m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m schema.decode_example(obj, token_per_repo_id=token_per_repo_id) \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1408\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\datasets\\features\\image.py:188\u001b[39m, in \u001b[36mImage.decode_example\u001b[39m\u001b[34m(self, value, token_per_repo_id)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     image = PIL.Image.open(BytesIO(bytes_))\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m image.load()  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image.getexif().get(PIL.Image.ExifTags.Base.Orientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     image = PIL.ImageOps.exif_transpose(image)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\anaconda3\\envs\\xai_proj_t2\\Lib\\site-packages\\PIL\\ImageFile.py:300\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    299\u001b[39m b = b + s\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m n, err_code = decoder.decode(b)\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m0\u001b[39m:\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_results = {d: [] for d in DOMAINS}\n",
    "all_results['avgs'] = []\n",
    "all_results['worst'] = []\n",
    "\n",
    "for _ in tqdm(range(NUM_SEEDS), desc=\"Seeds\"):\n",
    "    results = {}\n",
    "\n",
    "    for target_domain in tqdm(DOMAINS, desc=\"Target Domain\"):\n",
    "        model = build_model()\n",
    "        model = model.to(device)\n",
    "\n",
    "        optimizer = build_optimizer(model)\n",
    "        scheduler = build_scheduler(optimizer)\n",
    "\n",
    "        if not USE_PRETRAINED:\n",
    "            img_mean, img_std = office_home.get_normalization_stats(target_domain)\n",
    "            print(f\"Normalization values excluding domain {target_domain}:\\n\\tmean: {img_mean}\\n\\tstd: {img_std}\")\n",
    "            image_transform = T.Compose([\n",
    "                *AUGMENTATIONS,\n",
    "                T.Resize(256),\n",
    "                T.CenterCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=img_mean, std=img_std)\n",
    "            ])\n",
    "        else:\n",
    "            image_transform = pretrained_image_transform\n",
    "\n",
    "        train_loader, test_loader = office_home.get_data_loaders(target_domain, train_batch_size=BATCH_SIZE, transform=image_transform, shuffle_test=True, drop_last=True)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        for epoch in tqdm(range(1, EPOCHS + 1), desc=f\"Epoch ({target_domain})\"):\n",
    "            train_loss, train_acc = train(epoch, target_domain, train_loader, model, optimizer)\n",
    "            test_loss, test_acc = evaluate(test_loader, model)\n",
    "\n",
    "            writer.add_scalar(f\"Loss/Test/target={target_domain}\", test_loss, epoch)\n",
    "            writer.add_scalar(f\"Accuracy/Test/target={target_domain}\", test_acc, epoch)\n",
    "\n",
    "            scheduler.step(test_loss)\n",
    "\n",
    "            if best_loss - test_loss < EARLY_STOPPING_DELTA and (patience_counter := patience_counter+1) > EARLY_STOPPING_PATIENCE:\n",
    "                break\n",
    "\n",
    "            if test_loss < best_loss:\n",
    "                best_acc = test_acc\n",
    "                torch.save(model.state_dict(), f\"../checkpoints/mixstyle/best_{target_domain}.pt\")\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"../checkpoints/mixstyle/best_{target_domain}.pt\"))\n",
    "        _, acc = evaluate(test_loader, model, phase=\"final\")\n",
    "\n",
    "        results[target_domain] = acc\n",
    "\n",
    "    avg_acc = np.mean([*results.values()])\n",
    "    worst_case_acc = np.min([*results.values()])\n",
    "\n",
    "    for d in DOMAINS:\n",
    "        all_results[d].append(results[d])\n",
    "    all_results['avgs'].append(avg_acc)\n",
    "    all_results['worst'].append(worst_case_acc)\n",
    "\n",
    "print(\"Average Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.mean(all_results[d]):.4f}, std: {np.std(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['avgs']):.4f}, std: {np.std(all_results['avgs']):.4f}\\n\"\n",
    "      \"Worst-case Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.min(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['worst']):.4f}, std: {np.std(all_results['worst']):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:\n",
      "\tart_painting: 0.8934, std: 0.0036\n",
      "\tcartoon: 0.7596, std: 0.0041\n",
      "\tphoto: 0.9774, std: 0.0030\n",
      "\tsketch: 0.7298, std: 0.0048\n",
      "\ttotal: 0.8400, std: 0.0033\n",
      "Worst-case Accuracy:\n",
      "\tart_painting: 0.8887\n",
      "\tcartoon: 0.7564\n",
      "\tphoto: 0.9736\n",
      "\tsketch: 0.7235\n",
      "\ttotal: 0.7298, std: 0.0048\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.mean(all_results[d]):.4f}, std: {np.std(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['avgs']):.4f}, std: {np.std(all_results['avgs']):.4f}\\n\"\n",
    "      \"Worst-case Accuracy:\\n\" +\n",
    "      \"{}\".format(\"\".join(f\"\\t{d}: {np.min(all_results[d]):.4f}\\n\" for d in DOMAINS)) +\n",
    "      f\"\\ttotal: {np.mean(all_results['worst']):.4f}, std: {np.std(all_results['worst']):.4f}\"\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_proj_t2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
